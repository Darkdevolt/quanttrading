# app.py
import streamlit as st
import pandas as pd
import numpy as np
import csv # NÃ©cessaire pour le sniffer dans le loader, bien que la logique soit dans loader.py maintenant

# Importation des modules
from data import loader # Importe le module loader
from strategies import simple_ma
from backtesting import engine, metrics

# --- Configuration de l'interface Streamlit ---
st.set_page_config(layout="wide", page_title="BRVM Quant Backtest")

st.title("ğŸ“ˆ BRVM Quant Backtest")
st.markdown("""
Bienvenue sur l'outil d'analyse et de backtesting quantitatif pour la BRVM.
Chargez vos donnÃ©es historiques au format CSV pour commencer.
""")

# --- Initialisation de l'Ã©tat de session ---
# Utiliser st.session_state pour persister les donnÃ©es et les paramÃ¨tres
if 'uploaded_file_obj' not in st.session_state:
    st.session_state.uploaded_file_obj = None
if 'data' not in st.session_state:
    st.session_state.data = pd.DataFrame() # DataFrame traitÃ© et standardisÃ©
if 'all_columns' not in st.session_state:
    st.session_state.all_columns = [] # Noms des colonnes dÃ©tectÃ©es dans le fichier uploadÃ©
if 'column_mapping' not in st.session_state:
    # Mapping par dÃ©faut. L'utilisateur le modifiera.
    st.session_state.column_mapping = {
        "Date": "", "Open": "", "High": "", "Low": "", "Close": "", "Volume": ""
    }
if 'date_format_input' not in st.session_state:
    st.session_state.date_format_input = "" # Input utilisateur pour le format de date
if 'backtest_results' not in st.session_state:
    st.session_state.backtest_results = None # RÃ©sultats du backtest (courbe d'Ã©quitÃ©, mÃ©triques)


st.sidebar.header("ParamÃ¨tres Globaux")

# --- Section Upload de Fichier ---
st.sidebar.subheader("1. Chargement des DonnÃ©es")

# Callback pour gÃ©rer le cas oÃ¹ un NOUVEAU fichier est uploadÃ©
def handle_upload():
    """GÃ¨re l'upload d'un nouveau fichier et dÃ©tecte les colonnes."""
    uploaded_file = st.session_state['new_uploaded_file']
    st.session_state.uploaded_file_obj = uploaded_file # Stocker l'objet fichier

    if uploaded_file is not None:
        st.sidebar.info("Fichier uploadÃ©. DÃ©tection des colonnes...")
        try:
            # Lire juste l'en-tÃªte pour obtenir les noms de colonnes
            # Utiliser le mÃªme sniffer que dans le loader pour la cohÃ©rence
            uploaded_file.seek(0)
            sample_bytes = uploaded_file.read(2048)
            uploaded_file.seek(0)
            try: sample_text = sample_bytes.decode('utf-8')
            except UnicodeDecodeError: sample_text = sample_bytes.decode('latin-1', errors='ignore')

            separator = ','
            try:
                if sample_text.strip():
                    sniffer = csv.Sniffer()
                    dialect = sniffer.sniff(sample_text)
                    separator = dialect.delimiter
            except csv.Error:
                 # Fallback manuel si sniffer Ã©choue
                 uploaded_file.seek(0)
                 try: header_line_bytes = uploaded_file.readline()
                 except Exception: header_line_bytes = b'' # Handle potential read errors
                 try: header_line = header_line_bytes.decode('utf-8')
                 except UnicodeDecodeError: header_line = header_line_bytes.decode('latin-1', errors='ignore')
                 uploaded_file.seek(0)
                 if header_line and header_line.count(';') >= header_line.count(','): separator = ';'
                 else: separator = ','

            uploaded_file.seek(0) # Revenir au dÃ©but avant de lire l'en-tÃªte
            # Lire l'en-tÃªte avec pandas pour obtenir les noms de colonnes
            temp_df = pd.read_csv(uploaded_file, sep=separator, nrows=0) # Lire 0 ligne pour juste l'en-tÃªte
            st.session_state.all_columns = list(temp_df.columns)
            st.sidebar.success(f"Colonnes dÃ©tectÃ©es : {', '.join(st.session_state.all_columns)}")

            # RÃ©initialiser le mapping par dÃ©faut ou essayer de deviner
            st.session_state.column_mapping = {
                "Date": "", "Open": "", "High": "", "Low": "", "Close": "", "Volume": ""
            }
            # Tentative de mapping automatique basique
            for standard_name in st.session_state.column_mapping.keys():
                 # Chercher une colonne qui contient le nom standard (insensible Ã  la casse)
                 matching_cols = [col for col in st.session_state.all_columns if standard_name.lower() in col.lower()]
                 if matching_cols:
                      # Utiliser la premiÃ¨re correspondance trouvÃ©e
                      st.session_state.column_mapping[standard_name] = matching_cols[0]


        except Exception as e:
            st.sidebar.error(f"Erreur lors de la dÃ©tection des colonnes : {e}")
            st.session_state.all_columns = [] # Vider la liste des colonnes
            st.session_state.uploaded_file_obj = None # Invalider le fichier uploadÃ©
            st.session_state.column_mapping = { # RÃ©initialiser le mapping
                "Date": "", "Open": "", "High": "", "Low": "", "Close": "", "Volume": ""
            }


    else:
        # Si le fichier est retirÃ©
        st.session_state.uploaded_file_obj = None
        st.session_state.data = pd.DataFrame()
        st.session_state.all_columns = []
        st.session_state.column_mapping = {
            "Date": "", "Open": "", "High": "", "Low": "", "Close": "", "Volume": ""
        }
        st.session_state.date_format_input = ""
        st.session_state.backtest_results = None
        st.sidebar.info("Aucun fichier chargÃ©.")


# Le widget file_uploader met sa valeur dans la session_state via la key 'new_uploaded_file'
# et dÃ©clenche handle_upload si un fichier est sÃ©lectionnÃ© ou retirÃ©.
st.sidebar.file_uploader(
    "Chargez votre fichier CSV d'historique",
    type=['csv'],
    key='new_uploaded_file', # La valeur de l'uploader est stockÃ©e ici
    on_change=handle_upload # DÃ©clenche la fonction si la valeur change
)

# --- Section Mapping des Colonnes (AffichÃ©e si colonnes dÃ©tectÃ©es) ---
if st.session_state.all_columns:
    st.sidebar.subheader("2. Mapping des Colonnes")
    st.sidebar.write("Associez les colonnes de votre fichier aux noms standardisÃ©s.")

    options_list = [''] + st.session_state.all_columns # Define options once

    # CrÃ©er les selectbox pour le mapping
    for standard_name in st.session_state.column_mapping.keys():
        # Get the currently mapped column name safely
        mapped_col = st.session_state.column_mapping.get(standard_name, "")

        # Calculate the correct index for the selectbox
        selectbox_index = 0 # Default to index 0 ('')
        if mapped_col and mapped_col in st.session_state.all_columns:
            try:
                # Find index in original list and add 1 for the prepended ''
                original_index = st.session_state.all_columns.index(mapped_col)
                selectbox_index = original_index + 1
            except ValueError:
                # Should not happen due to 'in' check, but good practice
                selectbox_index = 0
        # Handle case where the mapping is explicitly set to '' after being something else
        elif not mapped_col:
            selectbox_index = 0


        # Create the selectbox with the calculated index
        selected_column = st.sidebar.selectbox(
            f"Colonne pour '{standard_name}'",
            options=options_list, # Use the defined options list
            index=selectbox_index, # Use the correctly calculated integer index
            key=f'map_{standard_name}' # ClÃ© unique pour chaque selectbox dans session_state
        )
        # Mettre Ã  jour le mapping dans la session_state quand une selectbox change
        # (This happens automatically thanks to the key and Streamlit's rerun logic)
        # Check if the value actually changed to update the session state correctly
        if st.session_state.column_mapping.get(standard_name) != selected_column:
             st.session_state.column_mapping[standard_name] = selected_column


    # Option pour spÃ©cifier le format de date
    st.sidebar.subheader("Format de Date (Optionnel)")
    st.session_state.date_format_input = st.sidebar.text_input(
        "SpÃ©cifiez le format de date (ex: %Y-%m-%d)",
        value=st.session_state.date_format_input,
        key='date_format_key',
        help="Laissez vide pour dÃ©tection automatique. SpÃ©cifiez si la dÃ©tection Ã©choue. Exemples: %Y-%m-%d, %d/%m/%Y"
    )

    # --- Bouton pour Traiter les DonnÃ©es ---
    # VÃ©rifier si toutes les colonnes requises sont mappÃ©es avant d'activer le bouton
    required_keys = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
    all_required_mapped = all(st.session_state.column_mapping.get(key) for key in required_keys)

    if st.sidebar.button("Processer les DonnÃ©es", disabled=not all_required_mapped):
        st.info("Traitement des donnÃ©es en cours...")
        # Assurer que le fichier est prÃªt Ã  Ãªtre lu Ã  nouveau
        if st.session_state.uploaded_file_obj:
            st.session_state.uploaded_file_obj.seek(0) # Important!

        # Appeler la fonction du loader avec le fichier uploadÃ© et le mapping
        processed_df = loader.load_and_process_data(
            st.session_state.uploaded_file_obj,
            st.session_state.column_mapping,
            st.session_state.date_format_input
        )

        if processed_df is not None and not processed_df.empty:
            st.session_state.data = processed_df # Stocker le DataFrame traitÃ©
            st.success("DonnÃ©es traitÃ©es avec succÃ¨s.")
            st.write("AperÃ§u des donnÃ©es traitÃ©es :")
            st.dataframe(st.session_state.data.head()) # Afficher les premiÃ¨res lignes
            st.info(f"DonnÃ©es disponibles du {st.session_state.data.index.min().date()} au {st.session_state.data.index.max().date()}.")

        else:
            st.session_state.data = pd.DataFrame() # Vider les donnÃ©es si le traitement Ã©choue
            st.error("Impossible de traiter les donnÃ©es avec le mapping et le format fournis. VÃ©rifiez vos sÃ©lections, le format de date et le contenu du fichier.")
            # Les messages d'erreur spÃ©cifiques sont dans les logs (ou dans le loader si vous y avez laissÃ© des prints)

# --- Section ParamÃ¨tres de Backtest (AffichÃ©e si donnÃ©es traitÃ©es) ---
if not st.session_state.data.empty:
    st.sidebar.subheader("3. ParamÃ¨tres du Backtest")

    # Utiliser les dates min/max des donnÃ©es traitÃ©es pour les sÃ©lecteurs de date
    min_date_data = st.session_state.data.index.min().date()
    max_date_data = st.session_state.data.index.max().date()

    col1, col2 = st.columns(2)

    with col1:
        start_date = st.date_input("Date de dÃ©but de l'analyse", value=min_date_data, min_value=min_date_data, max_value=max_date_data, key='start_date')
        end_date = st.date_input("Date de fin de l'analyse", value=max_date_data, min_value=min_date_data, max_value=max_date_data, key='end_date')

    with col2:
        initial_capital = st.number_input("Capital Initial", min_value=1000, value=100000, step=1000, key='initial_capital')
        short_window = st.slider("PÃ©riode MA Courte", min_value=1, max_value=100, value=40, key='short_window') # Min value should be 1 or more
        long_window = st.slider("PÃ©riode MA Longue", min_value=2, max_value=250, value=100, key='long_window') # Min value should be > short_window

    # --- Bouton de Lancement du Backtest ---
    if st.button("Lancer le Backtest"):
        # Validation des fenÃªtres de moyenne mobile
        if short_window >= long_window:
            st.error("La pÃ©riode de Moyenne Mobile Courte doit Ãªtre infÃ©rieure Ã  la pÃ©riode Longue.")
        else:
            st.info("ExÃ©cution du backtest en cours...")

            # Filtrer les donnÃ©es traitÃ©es par la plage de dates sÃ©lectionnÃ©e par l'utilisateur
            if pd.to_datetime(start_date) > pd.to_datetime(end_date):
                st.error("La date de dÃ©but de l'analyse ne peut pas Ãªtre postÃ©rieure Ã  la date de fin.")
            else:
                # Utiliser .loc avec des strings pour filtrer sur l'index DatetimeIndex
                # Assurer que les dates sont bien converties en datetime pour la comparaison
                start_dt = pd.to_datetime(start_date)
                end_dt = pd.to_datetime(end_date)

                # Filtrer en s'assurant que l'index est aussi datetime
                df_for_backtest = st.session_state.data[(st.session_state.data.index >= start_dt) & (st.session_state.data.index <= end_dt)].copy()


                if df_for_backtest.empty:
                    st.warning(f"Aucune donnÃ©e disponible dans la plage de dates sÃ©lectionnÃ©e ({start_date} au {end_date}).")
                    st.session_state.backtest_results = None
                elif len(df_for_backtest) <= long_window:
                     st.warning(f"Pas assez de donnÃ©es ({len(df_for_backtest)} jours) pour la pÃ©riode de MA longue ({long_window} jours) dans la plage sÃ©lectionnÃ©e.")
                     st.session_state.backtest_results = None
                else:
                    st.success(f"ExÃ©cution du backtest sur {len(df_for_backtest)} jours de donnÃ©es ({start_date} au {end_date}).")

                    # 1. Appliquer la stratÃ©gie pour gÃ©nÃ©rer les signaux
                    # Assumant que le loader a bien standardisÃ© la colonne en 'Prix' ou 'Close'.
                    # VÃ©rifions le nom de la colonne de clÃ´ture dans les donnÃ©es traitÃ©es.
                    # Si load_and_process_data retourne un df avec 'Prix', il faut le gÃ©rer.
                    # Supposons ici que load_and_process_data retourne un df avec la colonne 'Close' standardisÃ©e.
                    # Si ce n'est pas le cas, il faudra adapter soit le loader, soit ici.

                    # Assumons que la colonne standardisÃ©e est 'Close' comme attendu par simple_ma
                    if 'Close' not in df_for_backtest.columns:
                         st.error("La colonne 'Close' standardisÃ©e est manquante dans les donnÃ©es traitÃ©es. VÃ©rifiez le mapping et la fonction 'load_and_process_data'.")
                         st.session_state.backtest_results = None
                    else:
                        try:
                            df_strat = simple_ma.apply_strategy(df_for_backtest.copy(), short_window, long_window) # Passer une copie

                            # 2. ExÃ©cuter le backtest
                            # Le moteur run_backtest s'attend Ã  un df avec 'Close' et 'positions'.
                            equity_curve = engine.run_backtest(df_strat, initial_capital) # df_strat contient dÃ©jÃ  'Close' et 'positions'

                            if equity_curve is not None and not equity_curve.empty:
                                st.success("Backtest terminÃ©.")

                                # 3. Calculer les mÃ©triques de performance
                                performance_metrics = metrics.calculate_performance_metrics(equity_curve, initial_capital) # Passer le capital initial aux mÃ©triques

                                # Stocker les rÃ©sultats dans l'Ã©tat de session
                                st.session_state.backtest_results = {
                                    'equity_curve': equity_curve['Equity'], # Stocker seulement la sÃ©rie d'Ã©quitÃ©
                                    'performance_metrics': performance_metrics,
                                    'df_strat_for_plot': df_strat # Stocker aussi le df avec signaux pour le graphique
                                }

                            else:
                                st.error("Une erreur est survenue pendant l'exÃ©cution du backtest ou la courbe d'Ã©quitÃ© est vide.")
                                st.session_state.backtest_results = None
                        except Exception as e:
                            st.error(f"Erreur lors de l'application de la stratÃ©gie ou du backtest : {e}")
                            st.session_state.backtest_results = None


# --- Afficher les RÃ©sultats du Backtest (Si disponibles) ---
if st.session_state.backtest_results:
    st.header("RÃ©sultats du Backtest")

    results = st.session_state.backtest_results
    metrics_data = results['performance_metrics']
    equity_curve_series = results['equity_curve']
    df_strat_for_plot = results['df_strat_for_plot']

    # Afficher les mÃ©triques
    st.subheader("MÃ©triques de Performance")
    # Utiliser des colonnes pour mieux organiser l'affichage
    met_col1, met_col2 = st.columns(2)

    with met_col1:
        st.metric("Capital Initial", f"{metrics_data.get('Capital Initial', 'N/A'):,.0f}")
        st.metric("Capital Final", f"{metrics_data.get('Capital Final', 'N/A'):,.2f}")
        st.metric("Retour Total (%)", f"{metrics_data.get('Retour Total (%)', 'N/A'):.2f}%")
        st.metric("CAGR (%)", f"{metrics_data.get('CAGR (%)', 'N/A'):.2f}%")


    with met_col2:
        st.metric("Max Drawdown (%)", f"{metrics_data.get('Max Drawdown (%)', 'N/A'):.2f}%")
        st.metric("Ratio de Sharpe", f"{metrics_data.get('Sharpe Ratio', 'N/A'):.2f}")
        # Ajoutez d'autres mÃ©triques si disponibles (ex: VolatilitÃ©, Sortino, etc.)
        # st.metric("VolatilitÃ© Ann. (%)", f"{metrics_data.get('Annual Volatility (%)', 'N/A'):.2f}%")


    st.subheader("Courbe d'Ã‰quitÃ©")
    st.line_chart(equity_curve_series) # Afficher la sÃ©rie d'Ã©quitÃ©

    st.subheader("Prix de l'Action avec Signaux et Moyennes Mobiles")

    # PrÃ©parer le DataFrame pour le graphique des signaux/prix/MAs
    df_plot = df_strat_for_plot[['Close', 'Short_MA', 'Long_MA']].copy() # Inclure les MAs

    # S'assurer que 'positions' est numÃ©rique pour la comparaison
    df_strat_for_plot['positions'] = pd.to_numeric(df_strat_for_plot['positions'], errors='coerce')

    # Trouver les dates oÃ¹ un signal d'achat ou de vente a Ã©tÃ© gÃ©nÃ©rÃ© (changement de position)
    # Signal d'achat: position passe de 0 ou -1 Ã  1
    # Signal de vente: position passe de 1 ou 0 Ã  -1 (ou juste 1 Ã  -1 si on ne vend qu'aprÃ¨s achat)
    # Simplifions : signal d'achat lÃ  oÃ¹ position == 1 pour la premiÃ¨re fois aprÃ¨s != 1
    # signal de vente lÃ  oÃ¹ position == -1 pour la premiÃ¨re fois aprÃ¨s != -1

    # On prend les points oÃ¹ la position change
    buy_dates = df_strat_for_plot[(df_strat_for_plot['positions'] == 1) & (df_strat_for_plot['positions'].shift(1) != 1)].index
    sell_dates = df_strat_for_plot[(df_strat_for_plot['positions'] == -1) & (df_strat_for_plot['positions'].shift(1) != -1)].index


    # CrÃ©er des colonnes pour les marqueurs de signaux sur le graphique
    df_plot['Achat'] = np.nan # Utiliser np.nan pour que line_chart ne trace pas de lignes
    df_plot['Vente'] = np.nan

    # Placer les points de signal sur le graphique des prix (Ã  la valeur du prix 'Close')
    if not buy_dates.empty:
        df_plot.loc[buy_dates, 'Achat'] = df_plot.loc[buy_dates, 'Close']
    if not sell_dates.empty:
        df_plot.loc[sell_dates, 'Vente'] = df_plot.loc[sell_dates, 'Close']


    # Configurer le graphique avec st.line_chart
    # On trace Close, Short_MA, Long_MA comme lignes
    # On trace Achat et Vente comme points (st.line_chart le fait automatiquement si valeurs non-nan isolÃ©es)
    st.line_chart(df_plot[['Close', 'Short_MA', 'Long_MA', 'Achat', 'Vente']], use_container_width=True)
    st.markdown("*(Les points verts indiquent les achats, les points rouges indiquent les ventes lors des croisements de moyennes mobiles)*")


# --- Message si aucun fichier n'a encore Ã©tÃ© uploadÃ© ou traitÃ© ---
if st.session_state.uploaded_file_obj is None:
     st.info("Veuillez uploader un fichier CSV de donnÃ©es historiques dans la barre latÃ©rale pour commencer.")
elif st.session_state.data.empty and st.session_state.uploaded_file_obj is not None and 'Processer les DonnÃ©es' not in st.session_state.get('buttons_clicked', []): # Simple way to check if process was attempted
    # Message si fichier uploadÃ© mais pas encore traitÃ© ou traitement Ã©chouÃ©
    st.warning("Fichier uploadÃ©. Veuillez mapper les colonnes requises et cliquer sur 'Processer les DonnÃ©es' dans la barre latÃ©rale.")


st.sidebar.markdown("---") # SÃ©parateur visuel
st.sidebar.header("Ã€ Propos")
st.sidebar.info(
    "Cet outil permet de backtester une stratÃ©gie simple de croisement de moyennes mobiles sur des donnÃ©es historiques de la BRVM."
    "\n\nAssurez-vous que votre fichier CSV contient les colonnes nÃ©cessaires "
    "(Date, Ouverture, Plus Haut, Plus Bas, ClÃ´ture, Volume) "
    "et mappez-les correctement aprÃ¨s l'upload."
    "\n\nLes rÃ©sultats du backtest sont indicatifs et ne garantissent pas les performances futures."
)

# Pour suivre quel bouton a Ã©tÃ© cliquÃ© (simple gestion d'Ã©tat)
if 'buttons_clicked' not in st.session_state:
    st.session_state['buttons_clicked'] = []

# Log button clicks (peut Ãªtre utile pour le dÃ©bogage de l'Ã©tat)
if st.sidebar.button("Processer les DonnÃ©es", key="process_btn_state_tracker", disabled=not all_required_mapped if 'all_required_mapped' in locals() else True): # Need to check if var exists
    if 'Processer les DonnÃ©es' not in st.session_state['buttons_clicked']:
       st.session_state['buttons_clicked'].append('Processer les DonnÃ©es')
# Note: Streamlit reruns the script, so tracking button clicks needs careful state management.
# The logic above is a basic example and might need refinement depending on exact flow desired.
